{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CFB Week 10 Methods Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color='orange'>UPDATE COLLEGE FOOTBALL WEEK NUMBER HERE</font>\n",
    "Cell below contains week number and year for filtering API data. \n",
    "\n",
    "sat_day_num is used for getting the day of the month for this week's football games since don't want to bet on Thursday or Friday games\n",
    "\n",
    "df_name_prefix is how the file names for exported dataframes will be stored as so it is easy to know what I am looking at before opening and for sorting later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_num = 2022\n",
    "week_num = 11\n",
    "sat_day_num = 12\n",
    "df_name_prefix = 'cfb.' + str(year_num) + '.' + str(week_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfbd imports\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import cfbd\n",
    "from cfbd.rest import ApiException\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom formulas\n",
    "from cfbd_transform import betting_api_dataframe\n",
    "from equations import parlay_multiplier, amer_odds_to_prob, amer_odds_to_decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable. need to fill in own\n",
    "os.environ['api_key'] = config.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure API key authorization: ApiKeyAuth\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = os.getenv('api_key')\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import and Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting FBS ranking\n",
    "rankings_api = cfbd.RankingsApi(cfbd.ApiClient(configuration))\n",
    "rankings_api_response = rankings_api.get_rankings(year = year_num, \\\n",
    "                                                  week = week_num, \\\n",
    "                                                  season_type='regular')\n",
    "\n",
    "# save result into dataframe/ convert from json\n",
    "rankings_df = pd.DataFrame.from_records([t.to_dict() for t in rankings_api_response])\n",
    "\n",
    "# save as dataframe in better formatting\n",
    "rankings_df = pd.DataFrame.from_dict(rankings_df['polls'][0])\n",
    "\n",
    "# excluding polls for FCS and levels below that\n",
    "poll_exclude = ['FCS Coaches Poll','AFCA Division II Coaches Poll','AFCA Division III Coaches Poll']\n",
    "rankings_df = rankings_df[~rankings_df['poll'].isin(poll_exclude)]\n",
    "\n",
    "# coaches poll\n",
    "poll = 'Coaches Poll'\n",
    "index_num = rankings_df[rankings_df['poll']==poll].index[0]\n",
    "coaches_poll_df = pd.DataFrame(rankings_df[rankings_df['poll']==poll]['ranks'][index_num])\n",
    "coaches_poll_df['poll_name'] = poll\n",
    "\n",
    "# AP Top 25 poll\n",
    "poll = 'AP Top 25'\n",
    "index_num = rankings_df[rankings_df['poll']==poll].index[0]\n",
    "ap_poll_df = pd.DataFrame(rankings_df[rankings_df['poll']==poll]['ranks'][index_num])\n",
    "ap_poll_df['poll_name'] = poll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import Team Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting FBS ranking\n",
    "rankings_api = cfbd.RankingsApi(cfbd.ApiClient(configuration))\n",
    "rankings_api_response = rankings_api.get_rankings(year = year_num, \\\n",
    "                                                  week = week_num, \\\n",
    "                                                  season_type='regular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get team win loss records\n",
    "games_api = cfbd.GamesApi(cfbd.ApiClient(configuration))\n",
    "games_api_response = games_api.get_team_records(year = year_num)\n",
    "\n",
    "team_record_df = pd.DataFrame.from_records([g.to_dict() for g in games_api_response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse toal win loss column\n",
    "win_loss = []\n",
    "for i in team_record_df['total'].apply(pd.Series).columns.values:\n",
    "    win_loss.append('total_'+i)\n",
    "    \n",
    "total_win_loss_df = team_record_df['total'].apply(pd.Series)\n",
    "total_win_loss_df.columns = win_loss\n",
    "\n",
    "# append to original dataframe\n",
    "team_record_df = team_record_df.merge(total_win_loss_df, left_index=True, right_index=True).drop(columns=['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a W-L text field\n",
    "team_record_df['win_loss'] = team_record_df['total_wins'].astype(str) + '-' + \\\n",
    "    team_record_df['total_losses'].astype(str) + '-' + team_record_df['total_ties'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# home win %\n",
    "home_win_perc = team_record_df['home_games'].apply(pd.Series)[['games','wins']]\n",
    "home_win_perc['home_win_%'] = round((home_win_perc['wins'] / home_win_perc['games'])*100, 2)\n",
    "\n",
    "# append to original dataframe\n",
    "team_record_df = team_record_df.merge(home_win_perc['home_win_%'], left_index=True, right_index=True)#.drop(columns=['home_games'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# road win %\n",
    "away_win_perc = team_record_df['away_games'].apply(pd.Series)[['games','wins']]\n",
    "away_win_perc['away_win_%'] = round((away_win_perc['wins'] / away_win_perc['games'])*100, 2)\n",
    "\n",
    "# append to original dataframe\n",
    "team_record_df = team_record_df.merge(away_win_perc['away_win_%'], left_index=True, right_index=True)#.drop(columns=['away_games'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['team', 'conference','win_loss','home_win_%','away_win_%','expected_wins']\n",
    "team_record_df = team_record_df[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add ap poll inf to team record dataset\n",
    "team_record_df_v2 = pd.merge(team_record_df, ap_poll_df[['school', 'rank', 'first_place_votes', 'points']], \\\n",
    "         how = 'left', left_on = 'team', right_on='school')\n",
    "team_record_df_v2 = team_record_df_v2.rename(columns = {'rank': 'rank_ap', \n",
    "             'first_place_votes': 'first_place_votes_ap', \n",
    "             'points': 'points_ap'})\n",
    "team_record_df_v2.drop(columns='school', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add coaches poll info to team record dataset\n",
    "team_record_df_v3 = pd.merge(team_record_df_v2, coaches_poll_df[['school', 'rank', 'first_place_votes', 'points']], \\\n",
    "         how = 'left', left_on = 'team', right_on='school')\n",
    "team_record_df_v3 = team_record_df_v3.rename(columns = {'rank': 'rank_coaches', \n",
    "             'first_place_votes': 'first_place_votes_coaches', \n",
    "             'points': 'points_coaches'})\n",
    "team_record_df_v3.drop(columns='school', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_record_df_v4 = team_record_df_v3.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import ELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_api = cfbd.RatingsApi(cfbd.ApiClient(configuration))\n",
    "\n",
    "elo_api_response = ratings_api.get_elo_ratings(year = year_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_df = pd.DataFrame.from_records([t.to_dict() for t in elo_api_response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import Week 8 betting information and transform data\n",
    "\n",
    "1) Create an instance of betting API\n",
    "2) Create a start time column that parses the start date column\n",
    "2) Filter for Sat games only if needed\n",
    "3) Filter out Washington schools for now (change if in Vegas)\n",
    "4) Add win loss\n",
    "5) Add media info to see where to watch\n",
    "6) Add poll info\n",
    "7) Add in conference marker\n",
    "8) Merge ELO ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cfbd_transform function\n",
    "betting_df = betting_api_dataframe(configuration = configuration, \\\n",
    "                     week = week_num, \\\n",
    "                     year = year_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a start_time column\n",
    "betting_df['start_time'] = betting_df['start_date'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this week, only want to look at Saturday games\n",
    "betting_df = betting_df[betting_df['start_date'].dt.day==sat_day_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out Washington schools\n",
    "# hard coded for now. may want to pull in from API\n",
    "# save school names in WA\n",
    "wa_schools_list = ['Washington', 'Washington State']\n",
    "\n",
    "# filter out WA schools\n",
    "betting_df = betting_df[(~betting_df['home_team'].isin(wa_schools_list)) & \\\n",
    "                         (~betting_df['away_team'].isin(wa_schools_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add W-L info to betting dataframe\n",
    "\n",
    "# first do home team\n",
    "# rename win_loss to win_loss_home\n",
    "\n",
    "# drop team column\n",
    "home_team_cols = ['team','win_loss','home_win_%']\n",
    "betting_df = pd.merge(betting_df, team_record_df_v4[home_team_cols], \\\n",
    "                      how = 'left',\\\n",
    "                      left_on = 'home_team',\\\n",
    "                      right_on='team').drop(columns=['team']).rename(columns={'win_loss':'win_loss_home'})\n",
    "\n",
    "\n",
    "\n",
    "# then do away team\n",
    "away_team_cols = ['team','win_loss','away_win_%']\n",
    "betting_df = pd.merge(betting_df, team_record_df_v4[away_team_cols], \\\n",
    "                      how = 'left', \\\n",
    "                      left_on = 'away_team', \\\n",
    "                      right_on='team').drop(columns=['team']).rename(columns={'win_loss':'win_loss_away'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get media information for this week\n",
    "media = games_api.get_game_media(year = year_num, week = week_num, classification = 'fbs')\n",
    "media_df = pd.DataFrame.from_records([i.to_dict() for i in media])\n",
    "# join with betting dataframe\n",
    "betting_df = pd.merge(betting_df, media_df[['id','outlet']], how='left', left_on ='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add poll info to betting dataframe\n",
    "# first do home team\n",
    "\n",
    "# ap poll\n",
    "home_team_cols = ['school', 'rank']\n",
    "betting_df = pd.merge(betting_df, ap_poll_df[home_team_cols], \\\n",
    "         how = 'left',\\\n",
    "         left_on = 'home_team',\\\n",
    "         right_on='school').drop(columns=['school']).rename(columns={'rank':'ap_rank_home'}).fillna('')\n",
    "\n",
    "# coaches poll\n",
    "home_team_cols = ['school', 'rank']\n",
    "betting_df = pd.merge(betting_df, coaches_poll_df[home_team_cols], \\\n",
    "         how = 'left',\\\n",
    "         left_on = 'home_team',\\\n",
    "         right_on='school').drop(columns=['school']).rename(columns={'rank':'coaches_rank_home'}).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add poll info to betting dataframe\n",
    "# now away team\n",
    "\n",
    "# ap poll\n",
    "away_team_cols = ['school', 'rank']\n",
    "betting_df = pd.merge(betting_df, ap_poll_df[away_team_cols], \\\n",
    "         how = 'left',\\\n",
    "         left_on = 'away_team',\\\n",
    "         right_on='school').drop(columns=['school']).rename(columns={'rank':'ap_rank_away'}).fillna('')\n",
    "\n",
    "# coaches poll\n",
    "home_team_cols = ['school', 'rank']\n",
    "betting_df = pd.merge(betting_df, coaches_poll_df[away_team_cols], \\\n",
    "         how = 'left',\\\n",
    "         left_on = 'away_team',\\\n",
    "         right_on='school').drop(columns=['school']).rename(columns={'rank':'coaches_rank_away'}).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "values:\n",
    "1 = in conference game\n",
    "0 = out of conference game\n",
    "Nan = two independent schools are playing\n",
    "'''\n",
    "\n",
    "def in_conference (df):\n",
    "    if (df['home_conference'] == 'FBS Independents') & (df['away_conference'] == 'FBS Independents'):\n",
    "        return np.nan\n",
    "    elif df['home_conference'] == df['away_conference']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "betting_df['is_in_conference'] = betting_df.apply(in_conference, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elo ratings for away teams\n",
    "betting_df = pd.merge(betting_df, elo_df[['team','elo']], left_on='away_team', right_on='team', how='left')\n",
    "betting_df = betting_df.rename(columns={'elo':'elo_away'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elo for home teams\n",
    "betting_df = pd.merge(betting_df, elo_df[['team','elo']], left_on='home_team', right_on='team', how='left')\n",
    "betting_df = betting_df.rename(columns={'elo':'elo_home'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for calculating win probability from elo\n",
    "def get_away_elo(row):\n",
    "    exp = (row['elo_home'] - row['elo_away']) / 400\n",
    "    return 1 / (1 + 10**exp)\n",
    "\n",
    "def get_home_elo(row):\n",
    "    exp = (row['elo_away'] - row['elo_home']) / 400\n",
    "    return 1 / (1 + 10**exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_cols = ['home_team','away_team']\n",
    "betting_df['away_elo_prob'] = betting_df.apply(get_away_elo, axis = 1)\n",
    "betting_df['home_elo_prob'] = betting_df.apply(get_home_elo, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Export raw transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe to csv\n",
    "betting_df.to_csv('./output/' + df_name_prefix + '.raw.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bet Maker\n",
    "<b>Process:</b> \n",
    "\n",
    "*Note: Only moneylines will be used in parlay. Spread and O/U are more unpredictable in my opinion. \n",
    "1. Get games where the home team is an underdog, but the spread is less than 7.5 (can change this cutoff later if needed). Don't want a massive underdog with no chance of winning. For example, if Georgia plays @ Ohio, it is very unlikely and is not a good candidate to include in the parlay / I would never bet moneyline for that.\n",
    "    - Home field advantage is important in CFB, and I think it is a bigger influence on the outcome of the game than oddsmakers are including in their models\n",
    "2. Save the initial home underdog dataframe as a csv. Upload to Google Drive\n",
    "3. Review the initial home underdog output and make cuts. Do this by adding the home team name to the list in the cell below\n",
    "4. Output the new dataframe as a CSV and upload to Google Drive. Can do a little more digging for matchups and also find games to exclude. If need to exlcude repeat step 3 and add it to the cut list\n",
    "    - Example: Houston @ Navy 10/22/2022: Didn't like that one since I was sure Houston was going to win. Never sure how a team will play against triple option since not a lot of datapoints for it\n",
    "4. Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Casesars & ESPN Scraping\n",
    "Try to add caesars odds by scraping:\n",
    "- ESPN url format for games using game ID: https://www.espn.com/college-football/game?gameId=401411146\n",
    "- Moneyline is only available pre-game. Spread and O/U still available postgame\n",
    "- Can also pull in other information like matchup predictor (win prob %), numberFire, SPread cosensu pick, teamrankings, ATS\n",
    "\n",
    "Steps:\n",
    "1. Get game id's from cfdb data\n",
    "2. use game id's to make a list of urls\n",
    "3. for loop through list to get betting information from espn and win %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get game IDs from betting_df\n",
    "game_id_list = betting_df['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls using game id's\n",
    "url_list= []\n",
    "for i in game_id_list:\n",
    "    url_list.append('https://www.espn.com/college-football/game?gameId=' \\\n",
    "                    + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create lists to store home spread, home moneyline, away spread, and away moneyline\n",
    "home_spread_list = []\n",
    "home_moneyline_list = []\n",
    "away_spread_list = []\n",
    "away_moneyline_list = []\n",
    "home_espn_win_perc_list = []\n",
    "away_espn_win_perc_list = []\n",
    "\n",
    "for i in url_list:    \n",
    "    # create beautiful soup object for i\n",
    "    page = requests.get(i)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    # use the beautiful soup object to parse\n",
    "    results = soup.find(id='gamepackage-pick-center')\n",
    "    # find home team data and add to lists\n",
    "    # home team data\n",
    "    home_data = results.find_all('tr', class_='hometeam')\n",
    "    for i in home_data:\n",
    "        for count, x in enumerate(i.find_all('td', class_='score')):\n",
    "            if count == 2:\n",
    "                if (x.text.strip().replace(',','').replace('+','') == '--'):\n",
    "                    home_spread = np.nan\n",
    "                    home_spread_list.append(np.nan)\n",
    "                elif x.text.strip().replace(',','').replace('+','') == 'EVEN':\n",
    "                    home_spread = 0\n",
    "                    home_spread_list.append(home_spread)\n",
    "                else:\n",
    "                    home_spread = float(x.text.strip().replace(',','').replace('+',''))\n",
    "                    home_spread_list.append(home_spread)\n",
    "            if count == 3:\n",
    "                if x.text.strip().replace(',','').replace('+','') == '--':\n",
    "                    home_moneyline_list.append(np.nan)\n",
    "                else:\n",
    "                    home_moneylne = int(x.text.strip().replace(',','').replace('+',''))\n",
    "                    home_moneyline_list.append(home_moneylne)\n",
    "        \n",
    "        home_espn_win_perc_list.append(float(soup.find('span','value-home').text.replace('%', ''))/100)\n",
    "            \n",
    "    # find away team data and add to lists\n",
    "    # away content has the consensus picker data, so need to increase list indexes by 1\n",
    "    away_data = results.find_all('tr', class_='awayteam')\n",
    "    for i in away_data:\n",
    "        for count, x in enumerate(i.find_all('td', class_='score')):\n",
    "            if count == 3:\n",
    "                if x.text.strip().replace(',','').replace('+','') == '--':\n",
    "                    away_spread_list.append(np.nan)\n",
    "                elif x.text.strip().replace(',','').replace('+','') == 'EVEN':\n",
    "                    away_spread_list.append(0)\n",
    "                else:\n",
    "                    away_spread = float(x.text.strip().replace(',','').replace('+',''))\n",
    "                    away_spread_list.append(away_spread)            \n",
    "            if count == 4:\n",
    "                if x.text.strip().replace(',','').replace('+','') == '--':\n",
    "                    away_moneyline_list.append(np.nan)\n",
    "                else:\n",
    "                    away_moneylne = int(x.text.strip().replace(',','').replace('+',''))\n",
    "                    away_moneyline_list.append(away_moneylne)\n",
    "        away_espn_win_perc_list.append(float(soup.find('span','value-away').text.replace('%', ''))/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesars_df = pd.DataFrame(list(zip(game_id_list, home_spread_list, home_moneyline_list, away_spread_list, \\\n",
    "                                   away_moneyline_list, home_espn_win_perc_list, away_espn_win_perc_list)), \\\n",
    "             columns = ['game_id','home_spread_caesars','home_moneyline_caesars',\\\n",
    "                        'away_spread_caesars','away_moneyline_caesars','home_win_prob_espn','away_win_prob_espn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesars_df['home_moneyline_caesars'] = caesars_df['home_moneyline_caesars'].fillna(0)\n",
    "caesars_df['away_moneyline_caesars'] = caesars_df['away_moneyline_caesars'].fillna(0)\n",
    "\n",
    "caesars_df['home_win_prob_caesars'] = caesars_df['home_moneyline_caesars'].apply(amer_odds_to_prob).round(7)\n",
    "caesars_df['away_win_prob_caesars'] = caesars_df['away_moneyline_caesars'].apply(amer_odds_to_prob).round(7)\n",
    "\n",
    "\n",
    "#caesars_df['away_win_prob_no_vig']\n",
    "\n",
    "# caesars vig\n",
    "caesars_df['vig_caesars'] = caesars_df['home_win_prob_caesars'] + caesars_df['away_win_prob_caesars'] - 1\n",
    "\n",
    "# implied probabilities less vig see:\n",
    "# https://www.actionnetwork.com/education/juice\n",
    "# Team A Implied Probability / (Team A IP + Team B IP)\n",
    "caesars_df['home_win_prob_no_vig_caesars'] = caesars_df['home_win_prob_caesars'] / (caesars_df['home_win_prob_caesars'] + \\\n",
    "                                                                caesars_df['away_win_prob_caesars'])\n",
    "caesars_df['away_win_prob_no_vig_caesars'] = caesars_df['away_win_prob_caesars'] / (caesars_df['away_win_prob_caesars'] + \\\n",
    "                                                                caesars_df['home_win_prob_caesars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_df = pd.merge(betting_df, caesars_df, left_on='id', right_on='game_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get final probabilities and payouts:\n",
    "- If any in Caesars are blank or nan, use Bovada\n",
    "- If Bovada also blank or nan, exlude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesars_columns = ['id', 'home_moneyline_caesars', 'away_moneyline_caesars', 'home_spread_caesars']\n",
    "betting_df[caesars_columns]\n",
    "\n",
    "nan_spreads_caesars = betting_df[betting_df['home_spread_caesars'].isnull()].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "betting_df['home_moneyline_final'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final moneyline and spread columns that first look at caesars values, and if none use bovada\n",
    "betting_df['home_moneyline_final'] = betting_df['home_moneyline_caesars'] \n",
    "betting_df['away_moneyline_final'] = betting_df['away_moneyline_caesars'] \n",
    "betting_df['home_spread_final'] = betting_df['home_spread_caesars'] \n",
    "\n",
    "# replace moneyline of 0 with NaN. This handles no moneyline at Caesars\n",
    "# then use fill na to get moneyline from bovada in the cells where there are nulls\n",
    "# all moneylines should be filled. if both books don't have a value, the it will remain null\n",
    "betting_df['home_moneyline_final'] = betting_df['home_moneyline_final'].replace(0, np.nan)\n",
    "betting_df['home_moneyline_final'] = betting_df['home_moneyline_final'].fillna(betting_df['home_moneyline'])\n",
    "\n",
    "# repeat for away\n",
    "betting_df['away_moneyline_final'] = betting_df['away_moneyline_final'].replace(0, np.nan)\n",
    "betting_df['away_moneyline_final'] = betting_df['away_moneyline_final'].fillna(betting_df['away_moneyline'])\n",
    "\n",
    "# do spread\n",
    "betting_df['home_spread_final'] = betting_df['home_spread_final'].fillna(betting_df['spread'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate win probs based on moneyline odds\n",
    "betting_df['home_moneyline_final_temp'] = betting_df['home_moneyline_final'].fillna(0)\n",
    "betting_df['away_moneyline_final_temp'] = betting_df['away_moneyline_final'].fillna(0)\n",
    "\n",
    "betting_df['home_win_prob_final'] = betting_df['home_moneyline_final_temp'].apply(amer_odds_to_prob).round(7)\n",
    "betting_df['away_win_prob_final'] = betting_df['away_moneyline_final_temp'].apply(amer_odds_to_prob).round(7)\n",
    "\n",
    "\n",
    "#caesars_df['away_win_prob_no_vig']\n",
    "\n",
    "# caesars vig\n",
    "betting_df['vig_final'] = betting_df['home_win_prob_final'] + betting_df['away_win_prob_final'] - 1\n",
    "\n",
    "# implied probabilities less vig see:\n",
    "# https://www.actionnetwork.com/education/juice\n",
    "# Team A Implied Probability / (Team A IP + Team B IP)\n",
    "betting_df['home_win_prob_no_vig_final'] = betting_df['home_win_prob_final'] / (betting_df['home_win_prob_final'] + \\\n",
    "                                                                betting_df['away_win_prob_caesars'])\n",
    "betting_df['away_win_prob_no_vig_final'] = betting_df['away_win_prob_final'] / (betting_df['away_win_prob_final'] + \\\n",
    "                                                                betting_df['home_win_prob_final'])\n",
    "\n",
    "\n",
    "betting_df.drop(columns=['home_moneyline_final_temp', 'away_moneyline_final_temp'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Incorporate SP+ Data\n",
    "https://www.sbnation.com/college-football/2017/10/13/16457830/college-football-advanced-stats-analytics-rankings\n",
    "\n",
    "Google Sheets link with SP+ data: https://docs.google.com/spreadsheets/d/1llrN8luL0XWuP8Y-Pb1NXKU84JhXLeUPafy1RfITEDw/edit#gid=1482720576\n",
    "\n",
    "\n",
    "This link has SP+ and other models:\n",
    "https://www.ourdailybears.com/baylor-bears-football/2022/8/1/23271366/predictive-statistics-in-cfb-primer\n",
    "\n",
    "\n",
    "Note: SP+ has some different naming conventions. See cell below for differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Miami\n",
    "    - College Football Data = Miami\n",
    "    - SP+ = Miami-FL\n",
    "- Southern Miss\n",
    "    - College Football Data = Southern Miss\n",
    "    - SP+ = Southern Miss\n",
    "- Louisiana Monroe\n",
    "    - College Football Data = Louisiana Monroe\n",
    "    - SP+ = UL-Monroe\n",
    "- Louisiana\n",
    "    - College Football Data = Louisiana\n",
    "    - SP+ =  UL-Lafayette\n",
    "- San José State\n",
    "    - College Football Data = San José State\n",
    "    - SP+ = San Jose State\n",
    "- UMass\n",
    "    - College Football Data = UMass\n",
    "    - SP+ = Massachusetts\n",
    "- South Florida\n",
    "    - College Football Data = South Florida\n",
    "    - SP+ = USF\n",
    "- UT San Antonio\n",
    "    - College Football Data = UT San Antonio\n",
    "    - SP+ = UTSA\n",
    "- Hawai'i\n",
    "    - College Football Data = Hawai'i\n",
    "    - SP+ = Hawaii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp_plus_df = pd.read_csv('./input/SP+/2022 SP+ - Week 10 FBS.csv')\n",
    "\n",
    "# some values have ' vs. ' some have ' at '. replace vs. with at since had issues with doing two replaces\n",
    "sp_plus_df['Game_v2'] = sp_plus_df['Game']\n",
    "sp_plus_df['Game_v2'] = sp_plus_df['Game_v2'].str.replace(' vs. ', ' at ', regex = False)\n",
    "sp_plus_df['Game_v2'] = sp_plus_df['Game_v2'].str.split(' at ')\n",
    "\n",
    "# put home and away into own columns\n",
    "sp_plus_df[['away_team_sp','home_team_sp']] = pd.DataFrame(sp_plus_df['Game_v2'].tolist(), index= sp_plus_df.index)\n",
    "\n",
    "# convert win probability to float\n",
    "sp_plus_df['win_prob_float'] = pd.to_numeric(sp_plus_df['Win prob.'].str.strip('%'))\n",
    "\n",
    "\n",
    "# get home win probabilities based on the 'Proj. winner' column and win probability column\n",
    "home_win_prob = []\n",
    "for count, i in enumerate(sp_plus_df['home_team_sp'] == sp_plus_df['Proj. winner']):\n",
    "    if i == True:\n",
    "        home_win_prob.append(sp_plus_df.loc[count,'win_prob_float']/100)\n",
    "    elif i == False:\n",
    "        home_win_prob.append((100 - sp_plus_df.loc[count,'win_prob_float'])/100)\n",
    "sp_plus_df['home_win_prob_sp'] = home_win_prob\n",
    "\n",
    "# get away win probability\n",
    "away_win_prob = [(1-i) for i in home_win_prob]\n",
    "sp_plus_df['away_win_prob_sp'] = away_win_prob\n",
    "\n",
    "# check probabilities equal 1\n",
    "sum(sp_plus_df['away_win_prob_sp'] + sp_plus_df['home_win_prob_sp'] != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a join on home teams find naming anomolies\n",
    "test_merge_df = pd.merge(betting_df, sp_plus_df, left_on='away_team', right_on='away_team_sp', how='left')\n",
    "test_merge_df[test_merge_df['away_team_sp'].isnull()]['away_team'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a join on away teams find naming anomolies\n",
    "test_merge_df = pd.merge(betting_df, sp_plus_df, left_on='home_team', right_on='home_team_sp', how='left')\n",
    "test_merge_df[test_merge_df['home_team_sp'].isnull()]['home_team'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dict for naming conventions\n",
    "sp_rename_dict = {'Miami-FL':'Miami',\n",
    "                 'Southern Miss':'Southern Mississippi',\n",
    "                 'UL-Monroe':'Louisiana Monroe',\n",
    "                 'UL-Lafayette':'Louisiana',\n",
    "                 'San Jose State':'San José State',\n",
    "                 'Massachusetts':'UMass',\n",
    "                 'USF':'South Florida',\n",
    "                 'UTSA':'UT San Antonio',\n",
    "                 'Hawaii':'Hawai\\'i'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename home teams from SP+\n",
    "new_home_name_list = []\n",
    "for i in sp_plus_df['home_team_sp']:\n",
    "    if i in sp_rename_dict:\n",
    "        new_home_name_list.append(sp_rename_dict[i])\n",
    "    else:\n",
    "        new_home_name_list.append(i)\n",
    "\n",
    "# rename home teams from SP+\n",
    "new_away_name_list = []\n",
    "for i in sp_plus_df['away_team_sp']:\n",
    "    if i in sp_rename_dict:\n",
    "        new_away_name_list.append(sp_rename_dict[i])\n",
    "    else:\n",
    "        new_away_name_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_plus_df['away_team_sp_v2'] = new_away_name_list\n",
    "sp_plus_df['home_team_sp_v2'] = new_home_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get certain columns for joining\n",
    "sp_cols = ['Game','away_team_sp_v2','home_team_sp_v2','home_win_prob_sp','away_win_prob_sp','Proj. margin','Proj. winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_merge_df = pd.merge(betting_df, sp_plus_df, left_on='away_team', right_on='away_team_sp_v2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if there are any naming anomolies left\n",
    "len(test_merge_df[test_merge_df['away_team_sp'].isnull()]['away_team'].to_list())\n",
    "len(test_merge_df[test_merge_df['home_team_sp'].isnull()]['home_team'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_df = pd.merge(betting_df, sp_plus_df, left_on='away_team', right_on='away_team_sp_v2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "betting_df = betting_df.drop_duplicates(subset=['home_team', 'away_team'])\n",
    "\n",
    "# export to csv\n",
    "betting_df.to_csv('./output/'+ df_name_prefix  + 'raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Home Teams - Get teams to bet on if both ESPN and SP+ have good win probs for home team\n",
    "\n",
    "Here want to see home win probabilities for ESPN and SP+ to be more than 5% over the implied win prob % and the spread to be less than 7 points for favored away team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where win prob for espn and sp greater than caesars implied win% by more than 5%\n",
    "# game is close and is a home underdog\n",
    "\n",
    "display_cols = ['home_team','home_moneyline_final', 'home_spread_final', 'Proj. margin', 'home_win_prob_no_vig_final', 'home_win_prob_espn',\\\n",
    "                'home_win_prob_sp', 'home_elo_prob', 'win_loss_home','home_win_%', 'ap_rank_home','coaches_rank_home','away_team','away_win_prob_no_vig_final', \\\n",
    "                'away_win_prob_espn', 'away_win_prob_sp', 'away_elo_prob', 'win_loss_away', 'away_win_%','ap_rank_away', 'coaches_rank_away', 'start_time']\n",
    "\n",
    "# spread to be under for chance to win\n",
    "spread_limit = 7\n",
    "\n",
    "# percentage difference\n",
    "perc_limit = 0\n",
    "\n",
    "home_bets_df = betting_df[(betting_df['home_moneyline_final'] >= -110) &\\\n",
    "                          (betting_df['home_spread_final']<spread_limit)&\\\n",
    "                          # but need spread to be greater than 0 so is still underdog\n",
    "                          (betting_df['home_spread_final']>=0)&\\\n",
    "                          # win probabilities for ESPN and SP+ have to have to be greater than defined \n",
    "                          # (e.g. needs to be 5% more win probability than Caesars win prob\n",
    "                          ((betting_df['home_win_prob_espn'] - betting_df['home_win_prob_no_vig_final'] > perc_limit) & \\\n",
    "                           (betting_df['home_win_prob_sp'] - betting_df['home_win_prob_no_vig_final']> perc_limit))&\\\n",
    "                          # at least one of the three win probabilities are greater than 50%\n",
    "                          ((betting_df['home_win_prob_espn']>.5)|\\\n",
    "                           (betting_df['home_win_prob_sp']>.5)|\\\n",
    "                           (betting_df['home_elo_prob']>.5))][display_cols]\n",
    "\n",
    "home_bets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Away Teams - Both ESPN and SP+ have good win probs. Either ESPN or SP+ to be greater than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get games where the away team is not favored and have a greater than 47% chance at winning for espn and sp+\n",
    "display_cols = ['away_moneyline_final', 'away_team','away_win_prob_no_vig_final', 'away_win_prob_espn', \\\n",
    "                'away_win_prob_sp', 'away_elo_prob', 'win_loss_away', 'away_win_%',\\\n",
    "                'home_team','home_moneyline_final', 'home_spread_final', 'Proj. margin', 'home_win_prob_no_vig_final', 'home_win_prob_espn',\\\n",
    "                'home_win_prob_sp', 'home_elo_prob', 'win_loss_home','home_win_%', 'start_time']\n",
    "                \n",
    "# win perc floor\n",
    "win_perc_floor = .5\n",
    "\n",
    "away_bets_df = betting_df[(betting_df['away_moneyline_final'] > 0) &\\\n",
    "           ((betting_df['away_win_prob_espn']>win_perc_floor)|\\\n",
    "           (betting_df['away_win_prob_sp']>win_perc_floor))][display_cols]\n",
    "away_bets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merged pick list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Wrangle and export data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_bets_df_v2 = away_bets_df\n",
    "home_bets_df_v2 = home_bets_df\n",
    "away_display_cols = ['away_team', 'home_team', 'away_moneyline_final', 'home_spread_final', 'away_win_prob_no_vig_final', 'away_win_prob_espn', \\\n",
    "                'away_win_prob_sp', 'away_elo_prob', 'start_time']\n",
    "home_display_cols = ['home_team', 'away_team', 'home_moneyline_final', 'home_spread_final', 'home_win_prob_no_vig_final', 'home_win_prob_espn', \\\n",
    "                'home_win_prob_sp', 'home_elo_prob', 'start_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_bets_df_v2 = away_bets_df_v2[away_display_cols]\n",
    "away_bets_df_v2 = away_bets_df_v2.rename(columns = {'away_team':'picked_team', \\\n",
    "                                                    'away_moneyline_final':'moneyline', \\\n",
    "                                                    'away_win_prob_no_vig_final':'win_prob_no_vig', \\\n",
    "                                                    'away_win_prob_espn':'win_prob_espn', \\\n",
    "                                                    'away_win_prob_sp':'sp_prob', \\\n",
    "                                                    'away_elo_prob':'elo_prob', \\\n",
    "                                                    'home_spread_final': 'spread',\\\n",
    "                                                    'home_team':'opponent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_bets_df_v2 = home_bets_df_v2[home_display_cols]\n",
    "home_bets_df_v2 = home_bets_df_v2.rename(columns = {'home_team':'picked_team', \\\n",
    "                                                    'home_moneyline_final':'moneyline', \\\n",
    "                                                    'home_win_prob_no_vig_final':'win_prob_no_vig', \\\n",
    "                                                    'home_win_prob_espn':'win_prob_espn', \\\n",
    "                                                    'home_win_prob_sp':'sp_prob', \\\n",
    "                                                    'home_elo_prob':'elo_prob', \\\n",
    "                                                    'home_spread_final': 'spread',\\\n",
    "                                                    'away_team': 'opponent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks_df = pd.concat([home_bets_df_v2, away_bets_df_v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe to csv\n",
    "picks_df.to_csv('./output/' + df_name_prefix + '.picks.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See pick list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see new picks in dataframe legs in dataframe in this notebook\n",
    "picks_df.sort_values('start_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parlay Maker\n",
    "1) Parlay all the above into one parlay. This can be considered a \"100% win bonus\". Wager = \\$2 (minimum for parlay)\n",
    "2) Add some home favorites to parlay parlay 1. See how much the payout will increase with these heavy home favorites. Wager = \\$2 (minimum for parlay)\n",
    "3) Add 1 to 2 \"hail mary\" underdogs to parlay parlay 2. Want <b>realistic</b> underdogs, and ideally at home. These will increase payout exponentially with a minimum increased risk\n",
    "Wager = \\$2 (minimum for parlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parlay 1: Generate the parlay with the above picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a parlay list of moneylines\n",
    "#parlay_list = betting_df[betting_df['home_team'].isin(betting_df_v2['home_team'])]['home_moneyline'].to_list()\n",
    "parlay_list = picks_df['moneyline'].to_list()\n",
    "# save calculated multiplier for the parlay\n",
    "multiplier = int(parlay_multiplier(parlay_list))\n",
    "# save pretty list of teams\n",
    "team_parlay_list = picks_df['picked_team'].to_list()\n",
    "\n",
    "\n",
    "bet = 2\n",
    "payout = bet*multiplier\n",
    "\n",
    "print('Parlay 1:')\n",
    "print()\n",
    "\n",
    "print('Bet: ', \"${:0,.0f}\".format(bet))\n",
    "print('Number of legs: ' + str(len(parlay_list)))\n",
    "print('Multiplier: ', \"+{:0,.0f}\".format(multiplier))\n",
    "print()\n",
    "print('Payout: ', \"${:0,.0f}\".format(payout))\n",
    "\n",
    "print()\n",
    "print(team_parlay_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parlay 2: Add 1 to 2 \"Hail Mary\" picks\n",
    "\n",
    "Attempting the chance at a lotto parlay (very high payout on $2 bet). Do this by adding 1 to 2 underdogs so the payout increases.\n",
    "\n",
    "Want to see all of them, but sort by moneyline odds.\n",
    "\n",
    "Possible to select on \"after dark games\" for the opportunity to hedge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Home Underdogs\n",
    "Get home underdogs, but exclude those included in parlay 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_df[(~betting_df['home_team'].isin(team_parlay_list)) & (betting_df['home_moneyline_final']>0)][display_cols].sort_values('home_moneyline_final');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home hail mary selections\n",
    "# don't need to add any here if will add in hail mary away list below\n",
    "hail_mary_home_list = ['Notre Dame'] \n",
    "\n",
    "if len(hail_mary_home_list) == 0:\n",
    "    parlay_list = parlay_list\n",
    "    team_parlay_list = team_parlay_list\n",
    "elif len(hail_mary_home_list) > 0:\n",
    "    parlay_new_odds_list = betting_df[betting_df['home_team'].isin(hail_mary_home_list)]['home_moneyline_final'].to_list()\n",
    "    parlay_list = parlay_list + parlay_new_odds_list\n",
    "    team_parlay_list = team_parlay_list + hail_mary_home_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Away Underdogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# colummns to see in this dataframe\n",
    "display_cols = ['start_time','outlet', 'home_team','home_moneyline_final', 'home_win_prob_no_vig_final', \\\n",
    "                'win_loss_home','home_win_%', 'ap_rank_home','coaches_rank_home',\\\n",
    "                'away_team','away_moneyline_final','away_win_prob_no_vig_final', 'win_loss_away', 'away_win_%','ap_rank_away', 'coaches_rank_away',\\\n",
    "                'formatted_spread']\n",
    "betting_df[(betting_df['away_moneyline_final']>0)][display_cols].sort_values('away_moneyline_final');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away hail mary selections\n",
    "# don't need to add any here if added in hail mary home list\n",
    "hail_mary_away_list = ['Tennessee']\n",
    "\n",
    "if len(hail_mary_away_list) == 0:\n",
    "    parlay_list = parlay_list\n",
    "    team_parlay_list = team_parlay_list\n",
    "elif len(hail_mary_away_list) > 0:\n",
    "    parlay_new_odds_list = betting_df[betting_df['away_team'].isin(hail_mary_away_list)]['away_moneyline_final'].to_list()\n",
    "    parlay_list = parlay_list + parlay_new_odds_list\n",
    "    team_parlay_list = team_parlay_list + hail_mary_away_list\n",
    "\n",
    "multiplier = int(parlay_multiplier(parlay_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get new parlay payout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet = 2\n",
    "payout = bet*multiplier\n",
    "\n",
    "print('Parlay 3:')\n",
    "print()\n",
    "\n",
    "print('Bet: ', \"${:0,.0f}\".format(bet))\n",
    "print('Number of legs: ' + str(len(parlay_list)))\n",
    "print('Multiplier: ', \"+{:0,.0f}\".format(multiplier))\n",
    "print()\n",
    "print('Odds: ', \"+{:0,.0f}\".format(multiplier*100))\n",
    "print('Payout: ', \"${:0,.0f}\".format(payout))\n",
    "\n",
    "print()\n",
    "print(team_parlay_list)\n",
    "print()\n",
    "\n",
    "display_cols = ['start_time','outlet', 'home_team', 'home_moneyline_final', 'home_win_prob_no_vig_final', \\\n",
    "                'away_team', 'away_moneyline_final','away_win_prob_no_vig_final']\n",
    "# output final parlay to csv\n",
    "betting_df[(betting_df['home_team'].isin(team_parlay_list)) | (betting_df['away_team'].isin(team_parlay_list))]\\\n",
    "    [display_cols].to_csv('./output/' + df_name_prefix + '.parlay_final.csv', index = False)\n",
    "betting_df[(betting_df['home_team'].isin(team_parlay_list)) | (betting_df['away_team'].isin(team_parlay_list))][display_cols];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notes from trying to back test\n",
    "\n",
    "1. Records are not in line with week tested. They are only up to current time. If back test need to create new win loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data from ESPN's from pick center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.Session()\n",
    "\n",
    "# Create the payload\n",
    "payload = {'email':'re4693go@gmail.com',\n",
    "          'password':'BNg3!@^j4^wz'\n",
    "         }\n",
    "\n",
    "# Post the payload to the site to log in\n",
    "s = session.post(\"https://www.espn.com/login/?returnURL=https://www.espn.com/insider/pickcenter\", data=payload)\n",
    "\n",
    "# Navigate to the next page and scrape the data\n",
    "s = session.get('https://insider.espn.com/insider/pickcenter/ncf/game?gameid=401404103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://insider.espn.com/insider/pickcenter/ncf/game?gameid=401404103'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.find_all('div', class_='percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate # of games on espn website vs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check length of dataframe to see if it includes everything\n",
    "# compare against scraped espn scoreboard\n",
    "len(betting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'https://www.espn.com/college-football/schedule/_/week/10/year/2022/seasontype/2'\n",
    "espn_game_num = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://www.espn.com/college-football/schedule/_/week/10/year/2022/seasontype/2'\n",
    "scoreboard_url = 'https://www.espn.com/college-football/schedule/_/week/' + str(week_num) + \\\n",
    "    '/year/' + str(year_num) + '/seasontype/2'\n",
    "page = requests.get(scoreboard_url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "# use the beautiful soup object to parse\n",
    "#results = soup.find(id='gamepackage-pick-center')\n",
    "# find home team data and add to lists\n",
    "# home team data\n",
    "#home_data = results.find_all('tr', class_='hometeam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "day_data = soup.find_all('tr', class_='Table__TR Table__TR--sm Table__even')\n",
    "for i in day_data:\n",
    "    print(i)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
